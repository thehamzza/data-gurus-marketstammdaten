{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2dc552-2aa8-43a7-8ac8-3ae58f12693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.10/site-packages (2.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856c041c-b96f-43d0-9292-3d672f5d47aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for databricks\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import zipfile\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa494232-1412-469f-ac78-8741cf0cd62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fa4d7a99b40>\n"
     ]
    }
   ],
   "source": [
    "#Create SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"data-gurus\").getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d3b210-eb5d-45d3-abe5-592636ca02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for processing all the xml files in the dataset folder\n",
    "def names_of_xml_files(dataset_path):\n",
    "    '''\n",
    "\n",
    "    :param dataset_path: of zip file\n",
    "    :return: final list of files\n",
    "    '''\n",
    "    try:\n",
    "\n",
    "        zf = zipfile.ZipFile(dataset_path, \"r\")\n",
    "\n",
    "        xml_files = []\n",
    "        for file in zf.namelist():\n",
    "            if file.endswith(\".xml\"):\n",
    "                xml_files.append(os.path.join(file))\n",
    "\n",
    "        # print(xml_files)\n",
    "\n",
    "        new_list = []\n",
    "        for file in xml_files:\n",
    "            file = file[:-4]\n",
    "            new_list.append(file)\n",
    "\n",
    "        list_changed = [f.replace(\"_\", \"\") for f in new_list]\n",
    "        for i in range(0, 10):\n",
    "            list_changed = [f.replace(str(i), \"\") for f in list_changed]\n",
    "\n",
    "        final_list_of_files = list(set(list_changed))\n",
    "        return final_list_of_files\n",
    "    except Exception as e:\n",
    "        print(\"Error while capturing file names :\", e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "802a3c30-42c6-43de-85d1-ffe4573a990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give path of dataset and file name without the number\n",
    "def files_mask(dataset_path, filename):\n",
    "    '''\n",
    "    \n",
    "    :param dataset_path: provide dataset path of zip folder\n",
    "    :param filename: file name without extension type\n",
    "    :return: matching list with the same kind of files\n",
    "    '''\n",
    "    # get all files names in the datasetfolder\n",
    "\n",
    "    zf = zipfile.ZipFile(dataset_path, \"r\")\n",
    "    all_files = []\n",
    "    for file in zf.namelist():\n",
    "        if file.endswith(\".xml\"):\n",
    "            #[5:] removes DATA/ string from the beginning\n",
    "            all_files.append(file)\n",
    "\n",
    "    #all_files = [f for f in listdir(dataset_path) if isfile(join(dataset_path, f))]\n",
    "\n",
    "    regex_pattern = \".*\" + filename + \".*\"\n",
    "\n",
    "    match_list = []\n",
    "    for i in range(0, len(all_files)):\n",
    "        match = re.findall(regex_pattern, all_files[i])\n",
    "        if not match:\n",
    "            # if list is empty\n",
    "            pass\n",
    "        else:\n",
    "            match_list.append(match[0])\n",
    "\n",
    "    # print(\"Required Files in the Dataset: \", match_list)\n",
    "    return match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e17dc8-f13c-498e-991b-f8f9b9c0e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_dataframe_converter(dataset_path, xml_file):\n",
    "    '''\n",
    "    \n",
    "    :param dataset_path:zip folder path \n",
    "    :param xml_file: full file name with the extension\n",
    "    :return: dataframe\n",
    "    '''\n",
    "\n",
    "    zf = zipfile.ZipFile(dataset_path, \"r\")\n",
    "\n",
    "    #if xml_file in zf.namelist():\n",
    "    xml_file_open = zf.open(xml_file)\n",
    "    tree = ET.parse(xml_file_open)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    my_dict = {}\n",
    "    for elem in root:\n",
    "        for sub_elem in elem:\n",
    "            # check if key already exists in the dictionary\n",
    "            if my_dict.__contains__(sub_elem.tag):\n",
    "                my_dict[sub_elem.tag].append(sub_elem.text)\n",
    "            # else create the new key and append\n",
    "            else:\n",
    "                my_dict[sub_elem.tag] = []\n",
    "                my_dict[sub_elem.tag].append(sub_elem.text)\n",
    "             \n",
    "\n",
    "    df = pd.DataFrame.from_dict(my_dict, orient='index').transpose()\n",
    "\n",
    "    #print(df.dtypes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d526991-923f-4e81-aa5c-9be792180a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark data dictionary for each file type \n",
    "# TODO: please fill this schema dictionary for all files types, and check download\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, LongType, DoubleType\n",
    "schemaDict = {'anlageneegsolar': StructType([StructField('EegMaStRNummer', StringType(), True), \n",
    "                                             StructField('Registrierungsdatum', TimestampType(), True), \n",
    "                                             StructField('Zuschlagsnummer', StringType(), True), \n",
    "                                             StructField('MieterstromErsteZuordnungZuschlag', TimestampType(), True), \n",
    "                                             StructField('InstallierteLeistung', DoubleType(), True), \n",
    "                                             StructField('AusschreibungZuschlag', DoubleType(), True), \n",
    "                                             StructField('AnlagenkennzifferAnlagenregister_nv', LongType(), True), \n",
    "                                             StructField('ZugeordneteGebotsmenge', DoubleType(), True), \n",
    "                                             StructField('AnlageBetriebsstatus', LongType(), True), \n",
    "                                             StructField('DatumLetzteAktualisierung', StringType(), True), \n",
    "                                             StructField('RegistrierungsnummerPvMeldeportal_nv', LongType(), True), \n",
    "                                             StructField('VerknuepfteEinheitenMaStRNummern', StringType(), True), \n",
    "                                             StructField('MieterstromMeldedatum', TimestampType(), True), \n",
    "                                             StructField('EegInbetriebnahmedatum', TimestampType(), True), \n",
    "                                             StructField('AnlagenschluesselEeg', StringType(), True), \n",
    "                                             StructField('InanspruchnahmeZahlungNachEeg', DoubleType(), True), \n",
    "                                             StructField('AnlagenkennzifferAnlagenregister', StringType(), True), \n",
    "                                             StructField('MieterstromZugeordnet', DoubleType(), True), \n",
    "                                             StructField('RegistrierungsnummerPvMeldeportal', StringType(), True)]),\n",
    "              'anlageneegspeicher': StructType([StructField('EegMaStRNummer', StringType(), True), \n",
    "                                                StructField('Registrierungsdatum', TimestampType(), True), \n",
    "                                                StructField('EegInbetriebnahmedatum', TimestampType(), True), \n",
    "                                                StructField('VerknuepfteEinheitenMaStRNummern', StringType(), True), \n",
    "                                                StructField('DatumLetzteAktualisierung', TimestampType(), True)]), \n",
    "              \n",
    "              'anlagenstromspeicher': StructType([StructField('MaStRNummer', StringType(), True), \n",
    "                                                  StructField('DatumLetzteAktualisierung', TimestampType(), True), \n",
    "                                                  StructField('NutzbareSpeicherkapazitaet', DoubleType(), True), \n",
    "                                                  StructField('AnlageBetriebsstatus', LongType(), True), \n",
    "                                                  StructField('VerknuepfteEinheitenMaStRNummern', StringType(), True), \n",
    "                                                  StructField('Registrierungsdatum', TimestampType(), True)]),\n",
    "              \n",
    "              'einheitenstromspeicher': StructType([StructField('DatumLetzteAktualisierung', TimestampType(), True), \n",
    "                                                    StructField('GeplantesInbetriebnahmedatum', TimestampType(), True), \n",
    "                                                    StructField('Energietraeger', LongType(), True), \n",
    "                                                    StructField('NameStromerzeugungseinheit', StringType(), True), \n",
    "                                                    StructField('Ort', StringType(), True), \n",
    "                                                    StructField('Notstromaggregat', DoubleType(), True), \n",
    "                                                    StructField('Breitengrad', DoubleType(), True), \n",
    "                                                    StructField('Kraftwerksnummer_nv', LongType(), True), \n",
    "                                                    StructField('Registrierungsdatum', TimestampType(), True), \n",
    "                                                    StructField('Gemeindeschluessel', DoubleType(), True), \n",
    "                                                    StructField('BestandteilGrenzkraftwerk', DoubleType(), True), \n",
    "                                                    StructField('AnlagenbetreiberMastrNummer', StringType(), True), \n",
    "                                                    StructField('ZugeordnenteWirkleistungWechselrichter', DoubleType(), True), \n",
    "                                                    StructField('Land', LongType(), True), \n",
    "                                                    StructField('WeicDisplayName', StringType(), True), \n",
    "                                                    StructField('AcDcKoppelung', DoubleType(), True), \n",
    "                                                    StructField('Laengengrad', DoubleType(), True), \n",
    "                                                    StructField('PumpbetriebKontinuierlichRegelbar', DoubleType(), True), \n",
    "                                                    StructField('GenMastrNummer', StringType(), True), \n",
    "                                                    StructField('Gemarkung', StringType(), True), \n",
    "                                                    StructField('EinheitSystemstatus', LongType(), True), \n",
    "                                                    StructField('EinheitBetriebsstatus', LongType(), True), \n",
    "                                                    StructField('Einspeisungsart', DoubleType(), True), \n",
    "                                                    StructField('Hausnummer_nv', DoubleType(), True), \n",
    "                                                    StructField('Postleitzahl', StringType(), True), \n",
    "                                                    StructField('NichtVorhandenInMigriertenEinheiten', LongType(), True), \n",
    "                                                    StructField('Technologie', DoubleType(), True), \n",
    "                                                    StructField('Kraftwerksnummer', StringType(), True), \n",
    "                                                    StructField('Pumpspeichertechnologie', DoubleType(), True), \n",
    "                                                    StructField('Batterietechnologie', DoubleType(), True), \n",
    "                                                    StructField('FernsteuerbarkeitDv', DoubleType(), True), \n",
    "                                                    StructField('NetzbetreiberpruefungStatus', LongType(), True), \n",
    "                                                    StructField('DatumEndgueltigeStilllegung', TimestampType(), True), \n",
    "                                                    StructField('DatumDesBetreiberwechsels', TimestampType(), True), \n",
    "                                                    StructField('FernsteuerbarkeitDr', DoubleType(), True), \n",
    "                                                    StructField('DatumBeginnVoruebergehendeStilllegung', TimestampType(), True), \n",
    "                                                    StructField('NetzbetreiberpruefungDatum', TimestampType(), True), \n",
    "                                                    StructField('Weic', StringType(), True), \n",
    "                                                    StructField('EegMaStRNummer', StringType(), True), \n",
    "                                                    StructField('SpeMastrNummer', StringType(), True), \n",
    "                                                    StructField('DatumRegistrierungDesBetreiberwechsels', TimestampType(), True), \n",
    "                                                    StructField('Bundesland', DoubleType(), True), \n",
    "                                                    StructField('AnschlussAnHoechstOderHochSpannung', DoubleType(), True), \n",
    "                                                    StructField('Einsatzort', DoubleType(), True), \n",
    "                                                    StructField('Einsatzverantwortlicher', DoubleType(), True), \n",
    "                                                    StructField('PumpbetriebLeistungsaufnahme', DoubleType(), True), \n",
    "                                                    StructField('EegAnlagentyp', LongType(), True), \n",
    "                                                    StructField('LokationMaStRNummer', StringType(), True), \n",
    "                                                    StructField('FlurFlurstuecknummern', StringType(), True), \n",
    "                                                    StructField('Inbetriebnahmedatum', TimestampType(), True), \n",
    "                                                    StructField('StrasseNichtGefunden', DoubleType(), True), \n",
    "                                                    StructField('Bruttoleistung', DoubleType(), True), \n",
    "                                                    StructField('Adresszusatz', StringType(), True), \n",
    "                                                    StructField('Weic_nv', LongType(), True), \n",
    "                                                    StructField('Gemeinde', StringType(), True), \n",
    "                                                    StructField('Landkreis', StringType(), True), \n",
    "                                                    StructField('HausnummerNichtGefunden', StringType(), True), \n",
    "                                                    StructField('EinheitMastrNummer', StringType(), True), \n",
    "                                                    StructField('Nettonennleistung', DoubleType(), True), \n",
    "                                                    StructField('Hausnummer', StringType(), True), \n",
    "                                                    StructField('FernsteuerbarkeitNb', DoubleType(), True), \n",
    "                                                    StructField('DatumWiederaufnahmeBetrieb', TimestampType(), True), \n",
    "                                                    StructField('Strasse', StringType(), True), \n",
    "                                                    StructField('NettonennleistungDeutschland', DoubleType(), True)]),\n",
    "\n",
    "              'einheitensolar': StructType([StructField('EinheitMastrNummer', StringType(), True),\n",
    "                                            StructField('DatumLetzteAktualisierung', StringType(), True),\n",
    "                                            StructField('LokationMaStRNummer', StringType(), True),\n",
    "                                            StructField('NetzbetreiberpruefungStatus', StringType(), True), \n",
    "                                            StructField('NetzbetreiberpruefungDatum', StringType(), True), \n",
    "                                            StructField('AnlagenbetreiberMastrNummer', StringType(), True), \n",
    "                                            StructField('Land', StringType(), True), \n",
    "                                            StructField('Bundesland', LongType(), True), \n",
    "                                            StructField('Landkreis', StringType(), True), \n",
    "                                            StructField('Gemeinde', LongType(), True), \n",
    "                                            StructField('Gemeindeschluessel', LongType(), True), \n",
    "                                            StructField('Postleitzahl', LongType(), True), \n",
    "                                            StructField('Ort', StringType(), True), \n",
    "                                            StructField('Registrierungsdatum', TimestampType(), True), \n",
    "                                            StructField('Inbetriebnahmedatum', StringType(), True), \n",
    "                                            StructField('EinheitSystemstatus', LongType(), True), \n",
    "                                            StructField('EinheitBetriebsstatus', LongType(), True), \n",
    "                                            StructField('NichtVorhandenInMigriertenEinheiten', LongType(), True), \n",
    "                                            StructField('NameStromerzeugungseinheit', StringType(), True), \n",
    "                                            StructField('Weic_nv', LongType(), True), \n",
    "                                            StructField('Kraftwerksnummer_nv', LongType(), True), \n",
    "                                            StructField('Energietraeger', LongType(), True), \n",
    "                                            StructField('Bruttoleistung', LongType(), True), \n",
    "                                            StructField('Nettonennleistung', LongType(), True), \n",
    "                                            StructField('FernsteuerbarkeitNb', LongType(), True), \n",
    "                                            StructField('Einspeisungsart', LongType(), True), \n",
    "                                            StructField('ZugeordneteWirkleistungWechselrichter', LongType(), True), \n",
    "                                            StructField('GemeinsamerWechselrichterMitSpeicher', LongType(), True), \n",
    "                                            StructField('AnzahlModule', LongType(), True), \n",
    "                                            StructField('Lage', LongType(), True), \n",
    "                                            StructField('Leistungsbegrenzung', LongType(), True), \n",
    "                                            StructField('EinheitlicheAusrichtungUndNeigungswinkel', LongType(), True), \n",
    "                                            StructField('Hauptausrichtung', StringType(), True), \n",
    "                                            StructField('HauptausrichtungNeigungswinkel', LongType(), True), \n",
    "                                            StructField('EegMaStRNummer', StringType(), True), \n",
    "                                            StructField('Nutzungsbereich', LongType(), True), \n",
    "                                            StructField('Nebenausrichtung', LongType(), True), \n",
    "                                            StructField('NebenausrichtungNeigungswinkel', LongType(), True), \n",
    "                                            StructField('Gemarkung', StringType(), True), \n",
    "                                            StructField('FlurFlurstuecknummern', StringType(), True), \n",
    "                                            StructField('GeplantesInbetriebnahmedatum', TimestampType(), True), \n",
    "                                            StructField('Strasse', StringType(), True), \n",
    "                                            StructField('StrasseNichtGefunden', LongType(), True), \n",
    "                                            StructField('Hausnummer', StringType(), True), \n",
    "                                            StructField('Hausnummer_nv', LongType(), True), \n",
    "                                            StructField('HausnummerNichtGefunden', LongType(), True), \n",
    "                                            StructField('Laengengrad', LongType(), True), \n",
    "                                            StructField('Breitengrad', LongType(), True), \n",
    "                                            StructField('InAnspruchGenommeneFlaeche', LongType(), True), \n",
    "                                            StructField('Adresszusatz', StringType(), True), \n",
    "                                            StructField('FernsteuerbarkeitDv', LongType(), True), \n",
    "                                            StructField('FernsteuerbarkeitDr', LongType(), True), \n",
    "                                            StructField('ArtDerFlaecheIds', StringType(), True), \n",
    "                                            StructField('DatumDesBetreiberwechsels', TimestampType(), True), \n",
    "                                            StructField('DatumRegistrierungDesBetreiberwechsels', TimestampType(), True), \n",
    "                                            StructField('DatumBeginnVoruebergehendeStilllegung', TimestampType(), True), \n",
    "                                            StructField('AnschlussAnHoechstOderHochSpannung', LongType(), True),\n",
    "                                            StructField('DatumEndgueltigeStilllegung', TimestampType(), True),\n",
    "                                            StructField('InAnspruchGenommeneAckerflaeche', LongType(), True),\n",
    "                                            StructField('GenMastrNummer', LongType(), True),\n",
    "                                            StructField('Einsatzverantwortlicher', LongType(), True),\n",
    "                                            StructField('DatumWiederaufnahmeBetrieb', TimestampType(), True)])}\n",
    "#print(schemaDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "964d415b-555b-4e15-9378-5e8779741b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "#new main\n",
    "def main():\n",
    "    # change dataset path\n",
    "    #dataset_path = \"G:\\DATA GURUS WORK\\AAAA\\\"\n",
    "    dataset_path = \"/home/jovyan/work/AAAA.zip\"\n",
    "\n",
    "    #file_names = ['AnlagenEegSolar', 'AnlagenEegSpeicher', 'AnlagenStromSpeicher', 'EinheitenStromSpeicher', 'EinheitenSolar']\n",
    "    file_names = ['AnlagenEegSpeicher']\n",
    "\n",
    "    for i in range(0, len(file_names)):\n",
    "    \n",
    "        file_name = file_names[i]\n",
    "        \n",
    "        spark.sql(f\"drop table if exists marktstammdaten_{file_name.lower()}\")\n",
    "\n",
    "        print(\"Current File Type : \", file_name)\n",
    "\n",
    "        xml_files_list = files_mask(dataset_path, file_name)\n",
    "        print(\"XML FILES LIST: \", xml_files_list)\n",
    "\n",
    "        #print(schemaDict[file_name.lower()])      #TODO: delete it\n",
    "        \n",
    "        for xml_file in xml_files_list:\n",
    "\n",
    "            print(f\"Processing : {xml_file}\")\n",
    "            data = xml_to_dataframe_converter(dataset_path,xml_file)\n",
    "            # Create DataFrame\n",
    "            #df = pd.DataFrame(data)\n",
    "            #creating spark data frame            \n",
    "            sdf = spark.createDataFrame(data, schema=schemaDict[file_name.lower()] if file_name.lower() in schemaDict.keys() else None)\n",
    "            \n",
    "            # change database table name\n",
    "            table_name = file_name.lower()\n",
    "            table_name = \"marktstammdaten_\" + table_name\n",
    "\n",
    "            try:\n",
    "                sdf.write.mode(\"append\").saveAsTable(table_name)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred\")\n",
    "                print(e)\n",
    "                \n",
    "    print(\"Finished processing!!!!\")\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e39395f8-c9ef-42cb-b0ac-0230d6568bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current File Type :  AnlagenEegSpeicher\n",
      "XML FILES LIST:  ['AAAA/AnlagenEegSpeicher_2.xml', 'AAAA/AnlagenEegSpeicher_3.xml', 'AAAA/AnlagenEegSpeicher_4.xml', 'AAAA/AnlagenEegSpeicher_5.xml']\n",
      "Processing : AAAA/AnlagenEegSpeicher_2.xml\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "field Registrierungsdatum: TimestampType() can not accept object '2021-07-15T04:49:24.4362156' in type <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#main()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [8], line 33\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m data \u001b[38;5;241m=\u001b[39m xml_to_dataframe_converter(dataset_path,xml_file)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#df = pd.DataFrame(data)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#creating spark data frame            \u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m sdf \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschemaDict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mschemaDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# change database table name\u001b[39;00m\n\u001b[1;32m     36\u001b[0m table_name \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:891\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    888\u001b[0m     has_pandas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pandas\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m--> 891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSparkSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dataframe(\n\u001b[1;32m    895\u001b[0m     data, schema, samplingRatio, verifySchema  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    896\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/pandas/conversion.py:437\u001b[0m, in \u001b[0;36mSparkConversionMixin.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    436\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_from_pandas(data, schema, timezone)\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:936\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    934\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromRDD(data\u001b[38;5;241m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromLocal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    938\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(rdd\u001b[38;5;241m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:628\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;66;03m# make sure data could consumed multiple times\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 628\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    631\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferSchemaFromList(data, names\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:910\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe.<locals>.prepare\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;129m@no_type_check\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare\u001b[39m(obj):\n\u001b[0;32m--> 910\u001b[0m     \u001b[43mverify_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py:1722\u001b[0m, in \u001b[0;36m_make_type_verifier.<locals>.verify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify\u001b[39m(obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m verify_nullability(obj):\n\u001b[0;32m-> 1722\u001b[0m         \u001b[43mverify_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py:1700\u001b[0m, in \u001b[0;36m_make_type_verifier.<locals>.verify_struct\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1694\u001b[0m             new_msg(\n\u001b[1;32m   1695\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of object (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) does not match with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1696\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength of fields (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(obj), \u001b[38;5;28mlen\u001b[39m(verifiers))\n\u001b[1;32m   1697\u001b[0m             )\n\u001b[1;32m   1698\u001b[0m         )\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v, (_, verifier) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(obj, verifiers):\n\u001b[0;32m-> 1700\u001b[0m         \u001b[43mverifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1702\u001b[0m     d \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py:1722\u001b[0m, in \u001b[0;36m_make_type_verifier.<locals>.verify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify\u001b[39m(obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m verify_nullability(obj):\n\u001b[0;32m-> 1722\u001b[0m         \u001b[43mverify_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py:1716\u001b[0m, in \u001b[0;36m_make_type_verifier.<locals>.verify_default\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_default\u001b[39m(obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1715\u001b[0m     assert_acceptable_types(obj)\n\u001b[0;32m-> 1716\u001b[0m     \u001b[43mverify_acceptable_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py:1592\u001b[0m, in \u001b[0;36m_make_type_verifier.<locals>.verify_acceptable_types\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_acceptable_types\u001b[39m(obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;66;03m# subclass of them can not be fromInternal in JVM\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _acceptable_types[_type]:\n\u001b[0;32m-> 1592\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1593\u001b[0m             new_msg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m can not accept object \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m in type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (dataType, obj, \u001b[38;5;28mtype\u001b[39m(obj)))\n\u001b[1;32m   1594\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: field Registrierungsdatum: TimestampType() can not accept object '2021-07-15T04:49:24.4362156' in type <class 'str'>"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #main()\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbde4d0-e627-4f29-a2b0-f11c1139684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aes = spark.sql(\"select * from marktstammdaten_einheitensolar\")\n",
    "print(aes.count())\n",
    "print(aes.schema)\n",
    "aes.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
